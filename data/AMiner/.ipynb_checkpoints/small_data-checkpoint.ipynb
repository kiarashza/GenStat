{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. adjacency matrix 만들기\n",
    "# 2. feature vector 만들기\n",
    "# 3. train/valid/test 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author, paper, conference, term 하나의 dictionary로 만들기\n",
    "total_count = 0\n",
    "# author\n",
    "idx2authorname = {}\n",
    "author2idx = {}\n",
    "author_label = []\n",
    "with open('author_label.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        i += total_count\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        author2idx[int(line[0])] = i\n",
    "        idx2authorname[i] = line[2]\n",
    "        author_label.append([i,int(line[1])])\n",
    "total_count += len(author2idx)\n",
    "\n",
    "paper2idx = {}\n",
    "with open('paper_author.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        try:\n",
    "            author = author2idx[int(line[1])]\n",
    "            if int(line[0]) not in paper2idx:\n",
    "                paper2idx[int(line[0])] = len(paper2idx)+total_count\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2papername = {}\n",
    "# paper\n",
    "with open('paper2.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        try:\n",
    "            idx2papername[paper2idx[int(line[0])]] = line[1]\n",
    "        except:\n",
    "            pass\n",
    "total_count += len(paper2idx)\n",
    "idx2confname = {}\n",
    "conf2idx = {}\n",
    "# conf\n",
    "with open('conf.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        i += total_count\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        conf2idx[int(line[0])] = i\n",
    "        idx2confname[i] = line[1]\n",
    "total_count += len(conf2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {}\n",
    "with open('term.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    i=total_count\n",
    "    for line in lines:\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        if line[1] not in sp:\n",
    "            try:\n",
    "                tmp[int(line[0])] = line[1]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "term2idx = {}\n",
    "with open('paper_term.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        try:\n",
    "            paper = paper2idx[int(line[0])]\n",
    "            if tmp[int(line[1])] not in sp:\n",
    "                if int(line[1]) not in term2idx:\n",
    "                    term2idx[int(line[1])] = len(term2idx)+total_count\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "idx2termname = {}\n",
    "# term\n",
    "with open('term.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    i=total_count\n",
    "    for line in lines:\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        if line[1] not in sp:\n",
    "            try:\n",
    "                idx2termname[term2idx[int(line[0])]] = line[1]\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2name = {**idx2authorname, **idx2papername, **idx2confname, **idx2termname} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27194"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18405"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx2authorname)+len(idx2papername)+len(idx2confname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19645\n",
      "14328\n",
      "88420\n"
     ]
    }
   ],
   "source": [
    "# p-a\n",
    "indices_pa= []\n",
    "with open('paper_author.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        try:\n",
    "            paper = paper2idx[int(line[0])]\n",
    "            author = author2idx[int(line[1])]\n",
    "            indices_pa.append([paper,author])\n",
    "        except:\n",
    "            pass\n",
    "pa_num=len(indices_pa)\n",
    "print(pa_num)\n",
    "\n",
    "# p-c\n",
    "indices_pc= []\n",
    "with open('paper_conf.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        try:\n",
    "            indices_pc.append([paper2idx[int(line[0])],conf2idx[int(line[1])]])\n",
    "        except:\n",
    "            pass\n",
    "pc_num = len(indices_pc)\n",
    "print(pc_num)\n",
    "# p-t\n",
    "indices_pt= []\n",
    "with open('paper_term.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        try:\n",
    "            indices_pt.append([paper2idx[int(line[0])],term2idx[int(line[1])]])\n",
    "        except:\n",
    "            pass\n",
    "pt_num = len(indices_pt)\n",
    "print(pt_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27194"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_pa\n",
    "row = np.array(indices_pa)[:,0]\n",
    "col = np.array(indices_pa)[:,1]\n",
    "data = np.ones_like(row)\n",
    "A_pa = csr_matrix((data, (row, col)), shape=(len(idx2name), len(idx2name)))\n",
    "# A_pc\n",
    "row = np.array(indices_pc)[:,0]\n",
    "col = np.array(indices_pc)[:,1]\n",
    "data = np.ones_like(row)\n",
    "A_pc = csr_matrix((data, (row, col)), shape=(len(idx2name), len(idx2name)))\n",
    "# A_pt\n",
    "row = np.array(indices_pt)[:,0]\n",
    "col = np.array(indices_pt)[:,1]\n",
    "data = np.ones_like(row)\n",
    "A_pt = csr_matrix((data, (row, col)), shape=(len(idx2name), len(idx2name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = (A_ap*A_pt).todense()[:4057,-8789:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121763"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_feature = np.array(feature > 0, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95680"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_feat = mat_file['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n",
       "         11,   12,   13,   14,   15,   16,   17,   18,   19,   20,   21,\n",
       "         22,   23,   24,   25,   26,   27,   28,   29,   30,   31,   32,\n",
       "         33,   34,   35,   36,   37,   38,   39,   40,   41,   42,   43,\n",
       "         44,   45,   46,   47,   48,   49,   50,   51,   52,   53,   54,\n",
       "         55,   56,   57,   58,   59,   60,   61,   62,   63,   64,   65,\n",
       "         66,   67,   68,   69,   70,   71,   72,   73,   74,   75,   76,\n",
       "         77,   78,   79,   80,   81,   82,   83,   84,   85,   86,   87,\n",
       "         88,   89,   90,   91,   92,   93,   94,   95,   96,   97,   98,\n",
       "         99,  100,  101,  102,  103,  104,  105,  106,  107,  108,  109,\n",
       "        110,  111,  112,  113,  114,  115,  116,  117,  118,  119,  120,\n",
       "        121,  122,  123,  124,  125,  126,  127,  128,  129,  130,  131,\n",
       "        132,  133,  134,  135,  136,  137,  138,  139,  140,  141,  142,\n",
       "        143,  144,  145,  146,  147,  148,  149,  150,  151,  152,  153,\n",
       "        154,  155,  156,  157,  158,  159,  160,  161,  162,  163,  164,\n",
       "        165,  166,  167,  168,  169,  170,  171,  172,  173,  174,  175,\n",
       "        176,  177,  178,  179,  180,  181,  182,  183,  184,  185,  186,\n",
       "        187,  188,  189,  190,  191,  192,  193,  194,  195,  196,  197,\n",
       "        198,  199,  200,  201,  202,  203,  204,  205,  206,  207,  208,\n",
       "        209,  210,  211,  212,  213,  214,  215,  216,  217,  218,  219,\n",
       "        220,  221,  222,  223,  224,  225,  226,  227,  228,  229,  230,\n",
       "        231,  232,  233,  234,  235,  236,  237,  238,  239,  240,  241,\n",
       "        242,  243,  244,  245,  246,  247,  248,  249,  250,  251,  252,\n",
       "        253,  254,  255,  256,  257,  258,  259,  260,  261,  262,  263,\n",
       "        264,  265,  266,  267,  268,  269,  270,  271,  272,  273,  274,\n",
       "        275,  276,  277,  278,  279,  280,  281,  282,  283,  284,  285,\n",
       "        286,  287,  288,  289,  290,  291,  292,  293,  294,  295,  296,\n",
       "        297,  298,  299,  300,  301,  302,  303,  304,  305,  306,  307,\n",
       "        308,  309,  310,  311,  312,  313,  314,  315,  316,  317,  318,\n",
       "        319,  320,  321,  322,  323,  324,  325,  326,  327,  328,  329,\n",
       "        330,  331,  332,  333,  334,  335,  336,  337,  338,  339,  340,\n",
       "        341,  342,  343,  344,  345,  346,  347,  348,  349,  350,  351,\n",
       "        352,  353,  354,  355,  356,  357,  358,  359,  360,  361,  362,\n",
       "        363,  364,  365,  366,  367,  368,  369,  370,  371,  372,  373,\n",
       "        374,  375,  376,  377,  378,  379,  380,  381,  382,  383,  384,\n",
       "        385,  386,  387,  388,  389,  390,  391,  392,  393,  394,  395,\n",
       "        396,  397,  398,  399,  400,  401,  402,  403,  404,  405,  406,\n",
       "        407,  408,  409,  410,  411,  412,  413,  414,  415,  416,  417,\n",
       "        418,  419,  420,  421,  422,  423,  424,  425,  426,  427,  428,\n",
       "        429,  430,  431,  432,  433,  434,  435,  436,  437,  438,  439,\n",
       "        440,  441,  442,  443,  444,  445,  446,  447,  448,  449,  450,\n",
       "        451,  452,  453,  454,  455,  456,  457,  458,  459,  460,  461,\n",
       "        462,  463,  464,  465,  466,  467,  468,  469,  470,  471,  472,\n",
       "        473,  474,  475,  476,  477,  478,  479,  480,  481,  482,  483,\n",
       "        484,  485,  486,  487,  488,  489,  490,  491,  492,  493,  494,\n",
       "        495,  496,  497,  498,  499,  500,  501,  502,  503,  504,  505,\n",
       "        506,  507,  508,  509,  510,  511,  512,  513,  514,  515,  516,\n",
       "        517,  518,  519,  520,  521,  522,  523,  524,  525,  526,  527,\n",
       "        528,  529,  530,  531,  532,  533,  534,  535,  536,  537,  538,\n",
       "        539,  540,  541,  542,  543,  544,  545,  546,  547,  548,  549,\n",
       "        550,  551,  552,  553,  554,  555,  556,  557,  558,  559,  560,\n",
       "        561,  562,  563,  564,  565,  566,  567,  568,  569,  570,  571,\n",
       "        572,  573,  574,  575,  576,  577,  578,  579,  580,  581,  582,\n",
       "        583,  584,  585,  586,  587,  588,  589,  590,  591,  592,  593,\n",
       "        594,  595,  596,  597,  598,  599,  600,  601,  602,  603,  604,\n",
       "        605,  606,  607,  608,  609,  610,  611,  612,  613,  614,  615,\n",
       "        617,  618,  619,  620,  621,  624,  625,  627,  629,  630,  633,\n",
       "        634,  636,  641,  643,  644,  646,  649,  653,  658,  660,  661,\n",
       "        662,  664,  674,  677,  682,  684,  685,  686,  691,  692,  693,\n",
       "        699,  704,  705,  710,  711,  713,  719,  723,  725,  728,  729,\n",
       "        730,  732,  734,  736,  741,  745,  748,  751,  752,  753,  754,\n",
       "        757,  759,  762,  764,  766,  767,  768,  772,  775,  777,  779,\n",
       "        780,  781,  784,  785,  787,  788,  790,  796,  797,  799,  804,\n",
       "        806,  811,  813,  816,  818,  819,  821,  823,  825,  826,  828,\n",
       "        829,  832,  833,  836,  838,  839,  844,  845,  848,  849,  851,\n",
       "        855,  858,  860,  861,  862,  866,  869,  870,  872,  873,  875,\n",
       "        880,  881,  884,  888,  890,  892,  894,  895,  902,  903,  905,\n",
       "        925,  930,  933,  937,  943,  956,  962,  965,  967,  969,  972,\n",
       "        974,  993, 1001, 1003, 1012, 1014, 1018, 1031, 1039, 1042, 1046,\n",
       "       1054, 1060, 1073, 1085, 1088, 1090, 1098, 1102, 1104, 1105, 1110,\n",
       "       1117, 1122, 1123, 1127, 1129, 1140, 1158, 1160, 1164, 1166, 1175,\n",
       "       1177, 1186, 1190, 1191, 1194, 1206, 1212, 1219, 1220, 1222, 1223,\n",
       "       1230, 1250, 1253, 1254, 1261, 1264, 1266, 1270])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_file['train_idx'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(mat_feat==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_dict = {}\n",
    "for i in range(334):\n",
    "    for j in range(8789):\n",
    "        if np.sum(mat_feat[:,i] != author_feature[:,j]) == 0:\n",
    "            term_dict[i] = j\n",
    "            break\n",
    "        elif np.sum(mat_feat[:,i] != author_feature[:,j]) < 10:\n",
    "            term_dict[i] = j\n",
    "            break\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(term_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_vocab = np.sort(list(term_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    3,    4,    8,    9,   10,   11,   12,   13,   14,   16,\n",
       "         18,   19,   21,   25,   28,   30,   42,   43,   44,   48,   58,\n",
       "         60,   66,   67,   69,   74,   77,   82,   85,   86,   88,   89,\n",
       "         92,   93,   94,   99,  100,  101,  103,  110,  118,  127,  128,\n",
       "        129,  131,  133,  138,  139,  141,  149,  150,  151,  159,  164,\n",
       "        167,  168,  171,  172,  173,  174,  175,  177,  178,  179,  180,\n",
       "        182,  183,  184,  188,  189,  190,  194,  197,  203,  206,  211,\n",
       "        212,  214,  216,  217,  218,  220,  221,  222,  223,  225,  230,\n",
       "        231,  236,  238,  241,  243,  245,  248,  249,  253,  255,  256,\n",
       "        264,  269,  277,  279,  280,  285,  288,  289,  290,  291,  292,\n",
       "        296,  304,  305,  306,  308,  309,  310,  311,  318,  327,  338,\n",
       "        339,  340,  341,  345,  348,  350,  351,  356,  358,  361,  363,\n",
       "        378,  379,  383,  389,  392,  400,  413,  415,  417,  419,  424,\n",
       "        429,  436,  439,  451,  452,  458,  459,  463,  464,  466,  467,\n",
       "        472,  473,  474,  475,  483,  491,  509,  515,  516,  517,  523,\n",
       "        536,  539,  540,  563,  575,  576,  577,  580,  581,  589,  598,\n",
       "        600,  601,  607,  611,  614,  615,  616,  622,  633,  636,  643,\n",
       "        644,  648,  652,  654,  655,  672,  680,  709,  710,  719,  725,\n",
       "        726,  729,  739,  751,  758,  762,  764,  765,  766,  772,  775,\n",
       "        777,  792,  803,  808,  824,  831,  836,  845,  847,  856,  864,\n",
       "        869,  870,  890,  898,  914,  920,  936,  940,  954,  960,  964,\n",
       "        978,  985,  986,  992,  995, 1002, 1006, 1013, 1014, 1016, 1025,\n",
       "       1052, 1054, 1056, 1059, 1067, 1068, 1070, 1072, 1085, 1086, 1091,\n",
       "       1103, 1114, 1133, 1159, 1170, 1187, 1189, 1193, 1242, 1248, 1280,\n",
       "       1286, 1294, 1296, 1309, 1334, 1372, 1385, 1421, 1428, 1448, 1479,\n",
       "       1487, 1488, 1499, 1500, 1520, 1536, 1550, 1589, 1611, 1612, 1636,\n",
       "       1703, 1742, 1746, 1749, 1830, 1863, 1930, 1982, 1999, 2046, 2055,\n",
       "       2104, 2137, 2163, 2179, 2181, 2259, 2376, 2490, 2544, 2607, 2716,\n",
       "       2725, 2733, 2735, 2743, 2770, 2778, 2798, 2808, 2816, 2823, 2824,\n",
       "       2827, 2852, 2861, 2865, 2867, 2868, 2875, 2898, 2917, 2918, 2919,\n",
       "       2941, 2943, 3045, 3111])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problems\n",
      "learning\n",
      "theory\n",
      "one\n",
      "based\n",
      "knowledge\n",
      "representation\n",
      "languages\n",
      "integrating\n",
      "description\n",
      "action\n",
      "first\n",
      "results\n",
      "resolution\n",
      "partial\n",
      "using\n",
      "language\n",
      "ranking\n",
      "systems\n",
      "case\n",
      "querying\n",
      "applications\n",
      "two\n",
      "multi\n",
      "agent\n",
      "constraint\n",
      "semantic\n",
      "level\n",
      "structure\n",
      "robot\n",
      "clustering\n",
      "automatic\n",
      "generation\n",
      "control\n",
      "expert\n",
      "problem\n",
      "structured\n",
      "domain\n",
      "panel\n",
      "modeling\n",
      "reasoning\n",
      "rule\n",
      "logic\n",
      "programming\n",
      "approach\n",
      "decision\n",
      "qualitative\n",
      "algorithms\n",
      "model\n",
      "memory\n",
      "user\n",
      "construction\n",
      "interface\n",
      "algorithm\n",
      "discovery\n",
      "hierarchical\n",
      "reinforcement\n",
      "method\n",
      "trees\n",
      "real\n",
      "time\n",
      "comparison\n",
      "performance\n",
      "building\n",
      "models\n",
      "support\n",
      "tool\n",
      "use\n",
      "agents\n",
      "implementation\n",
      "query\n",
      "design\n",
      "domains\n",
      "value\n",
      "network\n",
      "intelligent\n",
      "semi\n",
      "supervised\n",
      "acquisition\n",
      "conceptual\n",
      "question\n",
      "multimedia\n",
      "induction\n",
      "information\n",
      "strategies\n",
      "retrieval\n",
      "world\n",
      "tree\n",
      "optimal\n",
      "solving\n",
      "human\n",
      "understanding\n",
      "interactive\n",
      "indexing\n",
      "spatial\n",
      "aggregation\n",
      "system\n",
      "features\n",
      "mining\n",
      "task\n",
      "boosting\n",
      "environments\n",
      "computing\n",
      "framework\n",
      "efficient\n",
      "bases\n",
      "updates\n",
      "simple\n",
      "planning\n",
      "non\n",
      "sets\n",
      "online\n",
      "optimization\n",
      "constraints\n",
      "web\n",
      "extraction\n",
      "summarization\n",
      "recognition\n",
      "motion\n",
      "belief\n",
      "context\n",
      "incremental\n",
      "multiple\n",
      "inference\n",
      "consistency\n",
      "causal\n",
      "space\n",
      "networks\n",
      "complexity\n",
      "objects\n",
      "local\n",
      "feature\n",
      "adaptive\n",
      "search\n",
      "searching\n",
      "queries\n",
      "rules\n",
      "order\n",
      "functional\n",
      "diagnosis\n",
      "towards\n",
      "environment\n",
      "topic\n",
      "detecting\n",
      "detection\n",
      "mapping\n",
      "oriented\n",
      "database\n",
      "analysis\n",
      "monitoring\n",
      "processing\n",
      "dynamic\n",
      "parallel\n",
      "approximate\n",
      "intelligence\n",
      "complex\n",
      "structures\n",
      "visual\n",
      "probabilistic\n",
      "generalized\n",
      "effective\n",
      "execution\n",
      "state\n",
      "bayesian\n",
      "recovery\n",
      "general\n",
      "markov\n",
      "classification\n",
      "tracking\n",
      "evaluation\n",
      "filtering\n",
      "collaborative\n",
      "measures\n",
      "services\n",
      "graphs\n",
      "sensitive\n",
      "cost\n",
      "new\n",
      "semantics\n",
      "evaluating\n",
      "robust\n",
      "mobile\n",
      "self\n",
      "programs\n",
      "quality\n",
      "approximation\n",
      "functions\n",
      "application\n",
      "large\n",
      "abstract\n",
      "exploiting\n",
      "natural\n",
      "improving\n",
      "via\n",
      "methods\n",
      "strategy\n",
      "k\n",
      "selection\n",
      "scale\n",
      "study\n",
      "data\n",
      "scheduling\n",
      "access\n",
      "object\n",
      "techniques\n",
      "class\n",
      "logical\n",
      "prediction\n",
      "generating\n",
      "computer\n",
      "sensor\n",
      "distributed\n",
      "technique\n",
      "function\n",
      "temporal\n",
      "extended\n",
      "graph\n",
      "continuous\n",
      "hybrid\n",
      "view\n",
      "statistical\n",
      "base\n",
      "management\n",
      "patterns\n",
      "set\n",
      "finding\n",
      "automated\n",
      "constrained\n",
      "machines\n",
      "engine\n",
      "image\n",
      "text\n",
      "databases\n",
      "pattern\n",
      "answering\n",
      "program\n",
      "supporting\n",
      "architecture\n",
      "behavior\n",
      "segmentation\n",
      "representations\n",
      "integration\n",
      "driven\n",
      "classifier\n",
      "discovering\n",
      "social\n",
      "relations\n",
      "computation\n",
      "neural\n",
      "content\n",
      "machine\n",
      "term\n",
      "without\n",
      "update\n",
      "reduction\n",
      "heterogeneous\n",
      "privacy\n",
      "spaces\n",
      "event\n",
      "relational\n",
      "views\n",
      "process\n",
      "word\n",
      "scalable\n",
      "cross\n",
      "flexible\n",
      "matching\n",
      "fast\n",
      "fuzzy\n",
      "maintenance\n",
      "linear\n",
      "high\n",
      "sequential\n",
      "random\n",
      "classifiers\n",
      "similarity\n",
      "path\n",
      "concept\n",
      "document\n",
      "decomposition\n",
      "structural\n",
      "sources\n",
      "combining\n",
      "regression\n",
      "kernel\n",
      "training\n",
      "association\n",
      "scheme\n",
      "stream\n",
      "research\n",
      "relevance\n",
      "distance\n",
      "vector\n",
      "preserving\n",
      "optimizing\n",
      "schema\n",
      "active\n",
      "peer\n",
      "issues\n",
      "sampling\n",
      "estimation\n",
      "line\n",
      "dimensional\n",
      "business\n",
      "transaction\n",
      "collection\n",
      "dependencies\n",
      "categorization\n",
      "xml\n",
      "frequent\n",
      "streams\n",
      "storage\n",
      "join\n",
      "feedback\n",
      "expansion\n",
      "documents\n",
      "multidimensional\n",
      "datasets\n",
      "visualization\n",
      "joins\n",
      "index\n",
      "transactions\n",
      "server\n",
      "page\n",
      "dbms\n",
      "top\n",
      "concurrency\n",
      "series\n",
      "nearest\n",
      "neighbor\n",
      "ir\n",
      "cluster\n",
      "sequences\n",
      "sql\n"
     ]
    }
   ],
   "source": [
    "for term in term_vocab:\n",
    "    print(idx2termname[term+18405])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "294\n",
      "317\n",
      "338\n",
      "387\n",
      "517\n",
      "557\n",
      "588\n",
      "773\n",
      "779\n",
      "870\n",
      "920\n",
      "1179\n",
      "1180\n",
      "1278\n",
      "1331\n",
      "1366\n",
      "1446\n",
      "1538\n",
      "1771\n",
      "1808\n",
      "1975\n",
      "2076\n",
      "2107\n",
      "2117\n",
      "2840\n",
      "2915\n",
      "2972\n",
      "3153\n",
      "3206\n",
      "3219\n",
      "3270\n",
      "3345\n",
      "3562\n",
      "3608\n",
      "3784\n",
      "3829\n",
      "3864\n",
      "3970\n"
     ]
    }
   ],
   "source": [
    "for i in range(mat_feat.shape[0]):\n",
    "    if np.sum(mat_feat[i]) ==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(334,)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(term_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(list(term_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(term_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4057, 8789)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4057,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_feature[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = A_pt.todense() + A_pt.transpose().todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "\n",
    "mat_file = io.loadmat('DBLP4057_GAT_with_idx.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = A_pa+A_pa.transpose()\n",
    "pc = A_pc+A_pc.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ap = A_pa.T\n",
    "A_cp = A_pc.T\n",
    "A_tp = A_pt.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "apcpa = (A_ap*A_pc*A_cp*A_pa).todense()\n",
    "tmp_apcpa = np.array(apcpa[:4057,:4057] > 0, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "apa = (A_ap*A_pa).todense()\n",
    "tmp_apa = np.array(apa[:4057,:4057] > 0, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "aptpa = (A_ap*A_pt*A_tp*A_pa).todense()\n",
    "tmp_aptpa = np.array(aptpa[:4057,:4057] > 0, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6769279.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(tmp_aptpa-(tmp_apa - np.eye(4057)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6769279"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(tmp_aptpa)-7056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7056.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(tmp_apa - np.eye(4057))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4993439.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.clip(tmp_apcpa-(tmp_apa - np.eye(4057)),0,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4993439.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(tmp_apcpa-(tmp_apa - np.eye(4057)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11113"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(tmp_apa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4963339.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mat_file['net_APCPA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tmp_apcpa-(tmp_apa - np.eye(4057))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 1., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 1., 1., 0.],\n",
       "       [0., 1., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 0., 1., 1.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_file['net_APCPA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44034"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=0\n",
    "for i in range(mat_file['net_APCPA'].shape[0]):\n",
    "    a += np.sum(result[i] != mat_file['net_APCPA'][i])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4963339.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mat_file['net_APCPA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4057, 4057)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000495"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4057"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(A_pa.nonzero()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Counter(np.array(indices_pt)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "words = []\n",
    "for word in a.keys():\n",
    "    if a[word] >=50:\n",
    "        cnt += 1\n",
    "        words.append(word)\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6786}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(idx2papername.keys())) - set(np.unique(A_pt.nonzero()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.unique(A_pt.nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6785"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2728]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6787"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.insert(b,2729,6786)[2730]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = np.unique(A_pt.nonzero()[0])\n",
    "papers = np.insert(papers, 2729,6786)\n",
    "paper_feature = A_pt[:,words][papers,:].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author features\n",
    "author_feature = []\n",
    "for i in range(0,len(idx2authorname)):\n",
    "    author_feature.append((np.sum(paper_feature[A_pa[:,i].nonzero()[0]-len(idx2papername)], axis=0)>0).tolist()[0])\n",
    "author_feature = np.array(author_feature, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conference features\n",
    "conf_features = []\n",
    "for i in list(idx2confname.keys()):\n",
    "    conf_features.append((np.sum(paper_feature[A_pc[:,i].nonzero()[0]-len(idx2papername)], axis=0)>0).tolist()[0])\n",
    "conf_features = np.array(conf_features, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18453x18453 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 14376 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14376"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx2papername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14376, 339)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = np.concatenate((author_feature,paper_feature,conf_features), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('node_features.pkl','wb') as f:\n",
    "    pickle.dump(node_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edges.pkl','wb') as f:\n",
    "    pickle.dump([A_pa,A_pc], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, ..., 3, 3, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array(list(author_label.values()))\n",
    "np.random.choice(lables, size=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(author_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 800\n",
    "num_valid = 400\n",
    "num_test = 2857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = author_label[:num_train]\n",
    "valid_data = author_label[num_train:num_train+num_valid]\n",
    "test_data = author_label[num_train+num_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labels.pkl','wb') as f:\n",
    "    pickle.dump([train_data,valid_data,test_data], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labels.pkl','wb') as f:\n",
    "    pickle.dump([A_pa,A_pc], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14375x339 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 50324 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[np.unique(A_pt.nonzero()[0]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge type: p-a, p-c, p-t\n",
    "# 1) p-a\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv('paper2.txt', sep='\\t', names=['idx','value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7601', 'Some Philosophical Problems with Formal Learning Theory.']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'a_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8616f7c17404>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0ma_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a_list' is not defined"
     ]
    }
   ],
   "source": [
    "with open('paper2.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip('\\n').split('\\t')\n",
    "        print(line)\n",
    "        a_list.append(str('A' + line[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(file):\n",
    "    f = pd.read_csv(file, sep='\\t', names=['idx','value'])\n",
    "    return f.to_dict()['value']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Adjacency(a,b,author=None,paper=None):\n",
    "    a_b = pd.read_csv(a+'_'+b+'.txt', sep='\\t', names=[a,b])\n",
    "    if author is not None:\n",
    "        a_b = a_b[a_b[b].isin(author)]\n",
    "    elif paper is not None:\n",
    "        a_b = a_b[a_b[a].isin(paper)]\n",
    "    row = a_b.values[:,0]\n",
    "    col = a_b.values[:,1]\n",
    "    data = np.ones_like(row)\n",
    "    A = csr_matrix((data, (row, col)))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4057"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = pd.read_csv('author_label.txt', sep='\\t', names=['idx','label','author'])\n",
    "len(author.idx.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pa = get_Adjacency('paper','author',author=author.idx.values)\n",
    "paper = np.unique(A_pa.nonzero()[0])\n",
    "A_pc = get_Adjacency('paper','conf',paper=paper)\n",
    "A_pt = get_Adjacency('paper','term',paper=paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<654270x438696 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19645 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<654270x4097 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 14328 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   7,    8,    9, ...,  902, 1653, 2229], dtype=int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8898"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(A_pt.nonzero()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4057"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(A_pa.nonzero()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(A_pc.nonzero()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14328"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<654270x13572 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 114273 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "\n",
    "mat_file = io.loadmat('ACM.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper -> bag-of-words -> keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yseongjun/anaconda3/envs/recsys/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1067: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(float(n_samples) / df) + 1.0\n"
     ]
    }
   ],
   "source": [
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "tfidf = transformer.fit_transform(A_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36008009, 0.28610998, 0.40625341, ..., 0.34087519, 0.29635594,\n",
       "       0.3099003 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ap = A_pa.T\n",
    "A_cp = A_pc.T\n",
    "A_tp = A_pt.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<438696x654270 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19645 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yseongjun/anaconda3/envs/recsys/lib/python3.6/site-packages/scipy/sparse/compressed.py:746: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "A_apa = A_ap.dot(A_pa)\n",
    "A_apa.setdiag(0)\n",
    "A_apa.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_label = dict(zip(author.idx.values, author.label.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "apa_ratio = {}\n",
    "apa_all_count = {}\n",
    "a1 = A_apa.nonzero()[0]\n",
    "a2 = A_apa.nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   226,    234,    234, ..., 438693, 438694, 438695], dtype=int32),\n",
       " array([   448,  26175, 114030, ..., 438694, 438693,  33972], dtype=int32))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_apa.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a1)):\n",
    "    if author_label[a1[i]] != author_label[a2[i]]:\n",
    "        if a1[i] not in apa_ratio:\n",
    "            apa_ratio[a1[i]] = 1\n",
    "        else:\n",
    "            apa_ratio[a1[i]] += 1\n",
    "    if a1[i] not in apa_all_count:\n",
    "        apa_all_count[a1[i]] = 1\n",
    "    else:\n",
    "        apa_all_count[a1[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in apa_ratio.keys():\n",
    "    apa_ratio[key] /= apa_all_count[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{867: 0.6666666666666666,\n",
       " 934: 0.6666666666666666,\n",
       " 1102: 1.0,\n",
       " 1256: 0.5,\n",
       " 1314: 0.5,\n",
       " 1705: 0.6,\n",
       " 1842: 0.3333333333333333,\n",
       " 1844: 0.5,\n",
       " 1975: 0.5,\n",
       " 2290: 0.8,\n",
       " 2525: 0.2,\n",
       " 2588: 0.5,\n",
       " 3293: 1.0,\n",
       " 3460: 0.14285714285714285,\n",
       " 3675: 0.5,\n",
       " 3759: 1.0,\n",
       " 4225: 0.3333333333333333,\n",
       " 4239: 0.2,\n",
       " 4386: 0.8,\n",
       " 4469: 0.3333333333333333,\n",
       " 4595: 1.0,\n",
       " 4606: 1.0,\n",
       " 4642: 0.3333333333333333,\n",
       " 4681: 0.25,\n",
       " 4840: 0.75,\n",
       " 4842: 0.3333333333333333,\n",
       " 4865: 0.16666666666666666,\n",
       " 4968: 0.5,\n",
       " 5160: 0.5,\n",
       " 5173: 1.0,\n",
       " 5269: 0.2,\n",
       " 5586: 1.0,\n",
       " 6207: 0.14285714285714285,\n",
       " 6330: 0.14285714285714285,\n",
       " 6613: 0.3333333333333333,\n",
       " 7277: 0.52,\n",
       " 7338: 0.3333333333333333,\n",
       " 7907: 0.5,\n",
       " 8242: 1.0,\n",
       " 8320: 0.25,\n",
       " 8756: 0.36363636363636365,\n",
       " 8928: 0.3333333333333333,\n",
       " 8966: 0.3333333333333333,\n",
       " 9000: 0.8,\n",
       " 9096: 0.5,\n",
       " 9153: 1.0,\n",
       " 9252: 0.6153846153846154,\n",
       " 9329: 0.6666666666666666,\n",
       " 9391: 0.4,\n",
       " 9465: 0.75,\n",
       " 9485: 0.6,\n",
       " 9518: 0.5,\n",
       " 9521: 1.0,\n",
       " 9784: 0.4444444444444444,\n",
       " 9791: 0.4444444444444444,\n",
       " 9915: 0.75,\n",
       " 10003: 0.3333333333333333,\n",
       " 10299: 0.6666666666666666,\n",
       " 10431: 0.4,\n",
       " 10497: 0.5,\n",
       " 11721: 1.0,\n",
       " 11724: 1.0,\n",
       " 11758: 0.5,\n",
       " 11964: 0.5,\n",
       " 11983: 1.0,\n",
       " 12269: 0.08333333333333333,\n",
       " 12284: 0.2,\n",
       " 12309: 0.5,\n",
       " 12316: 0.2,\n",
       " 12317: 0.14285714285714285,\n",
       " 12351: 1.0,\n",
       " 12403: 0.5,\n",
       " 12631: 0.5,\n",
       " 12729: 0.3333333333333333,\n",
       " 13075: 1.0,\n",
       " 13101: 1.0,\n",
       " 13209: 1.0,\n",
       " 13319: 0.9090909090909091,\n",
       " 13380: 0.75,\n",
       " 13401: 0.6,\n",
       " 13485: 1.0,\n",
       " 13548: 0.5,\n",
       " 13801: 0.3333333333333333,\n",
       " 13848: 0.3333333333333333,\n",
       " 14117: 0.5555555555555556,\n",
       " 14180: 0.5,\n",
       " 14236: 0.3333333333333333,\n",
       " 14481: 0.5,\n",
       " 15083: 0.3333333333333333,\n",
       " 15206: 0.2857142857142857,\n",
       " 15294: 1.0,\n",
       " 15324: 0.3333333333333333,\n",
       " 15410: 0.1111111111111111,\n",
       " 15414: 0.8333333333333334,\n",
       " 15454: 1.0,\n",
       " 15463: 0.3333333333333333,\n",
       " 15470: 0.5,\n",
       " 15474: 1.0,\n",
       " 15475: 0.6,\n",
       " 15481: 0.7714285714285715,\n",
       " 15493: 0.5,\n",
       " 15514: 0.3333333333333333,\n",
       " 15516: 1.0,\n",
       " 15574: 1.0,\n",
       " 15575: 0.14285714285714285,\n",
       " 15582: 0.3333333333333333,\n",
       " 15667: 1.0,\n",
       " 15672: 0.5,\n",
       " 15706: 1.0,\n",
       " 15756: 0.3333333333333333,\n",
       " 15787: 0.5833333333333334,\n",
       " 15794: 1.0,\n",
       " 15807: 0.5,\n",
       " 15816: 0.3333333333333333,\n",
       " 15839: 0.4,\n",
       " 15846: 0.25,\n",
       " 15863: 0.5,\n",
       " 15926: 0.5,\n",
       " 15946: 0.13793103448275862,\n",
       " 15950: 0.5,\n",
       " 15997: 0.75,\n",
       " 16039: 0.3333333333333333,\n",
       " 16048: 0.3333333333333333,\n",
       " 16053: 0.5,\n",
       " 16055: 1.0,\n",
       " 16057: 1.0,\n",
       " 16058: 0.1111111111111111,\n",
       " 16067: 0.2,\n",
       " 16092: 0.3333333333333333,\n",
       " 16094: 0.3333333333333333,\n",
       " 16135: 0.5,\n",
       " 16162: 0.6666666666666666,\n",
       " 16224: 0.5,\n",
       " 16226: 0.3333333333333333,\n",
       " 16231: 0.6666666666666666,\n",
       " 16260: 0.3333333333333333,\n",
       " 16269: 1.0,\n",
       " 16270: 0.6666666666666666,\n",
       " 16279: 0.5,\n",
       " 16285: 0.5,\n",
       " 16328: 0.5,\n",
       " 16330: 1.0,\n",
       " 16334: 0.4,\n",
       " 16397: 1.0,\n",
       " 16422: 0.3333333333333333,\n",
       " 16490: 0.5,\n",
       " 16503: 0.5,\n",
       " 16559: 1.0,\n",
       " 16564: 0.14285714285714285,\n",
       " 16567: 1.0,\n",
       " 16681: 0.46153846153846156,\n",
       " 16695: 0.45454545454545453,\n",
       " 16714: 0.4,\n",
       " 16721: 0.5,\n",
       " 16737: 0.25,\n",
       " 16766: 0.3333333333333333,\n",
       " 16778: 0.25,\n",
       " 16782: 0.5,\n",
       " 16849: 0.25,\n",
       " 16850: 0.875,\n",
       " 16911: 0.5,\n",
       " 16964: 0.3333333333333333,\n",
       " 16973: 0.3333333333333333,\n",
       " 17014: 0.5,\n",
       " 17015: 0.6,\n",
       " 17019: 1.0,\n",
       " 17057: 0.5,\n",
       " 17076: 0.6,\n",
       " 17107: 0.5,\n",
       " 17148: 0.25,\n",
       " 17240: 0.5,\n",
       " 17251: 0.4444444444444444,\n",
       " 17423: 0.2,\n",
       " 17424: 0.3333333333333333,\n",
       " 17457: 1.0,\n",
       " 17487: 1.0,\n",
       " 17530: 0.3333333333333333,\n",
       " 17633: 0.21428571428571427,\n",
       " 17646: 0.5,\n",
       " 17668: 1.0,\n",
       " 17719: 0.5,\n",
       " 17762: 1.0,\n",
       " 17764: 0.3333333333333333,\n",
       " 17818: 1.0,\n",
       " 17829: 0.5,\n",
       " 17840: 0.75,\n",
       " 17841: 0.3333333333333333,\n",
       " 17996: 0.3333333333333333,\n",
       " 18032: 0.2,\n",
       " 18074: 0.3333333333333333,\n",
       " 18099: 0.8,\n",
       " 18104: 0.5,\n",
       " 18125: 0.2857142857142857,\n",
       " 18148: 1.0,\n",
       " 18239: 1.0,\n",
       " 18330: 1.0,\n",
       " 18505: 0.25,\n",
       " 18562: 1.0,\n",
       " 18598: 1.0,\n",
       " 18733: 0.3333333333333333,\n",
       " 18752: 0.5,\n",
       " 18825: 1.0,\n",
       " 18869: 0.5,\n",
       " 18883: 0.4444444444444444,\n",
       " 18897: 0.8,\n",
       " 18904: 0.5,\n",
       " 18917: 0.3333333333333333,\n",
       " 19014: 0.14285714285714285,\n",
       " 19016: 0.5,\n",
       " 19042: 1.0,\n",
       " 19240: 0.3333333333333333,\n",
       " 19315: 1.0,\n",
       " 19373: 1.0,\n",
       " 19399: 0.6666666666666666,\n",
       " 19401: 1.0,\n",
       " 19435: 1.0,\n",
       " 19445: 1.0,\n",
       " 19446: 0.38461538461538464,\n",
       " 19512: 1.0,\n",
       " 19592: 0.17647058823529413,\n",
       " 19614: 1.0,\n",
       " 19617: 0.18181818181818182,\n",
       " 19618: 0.75,\n",
       " 19627: 0.07142857142857142,\n",
       " 19656: 0.3333333333333333,\n",
       " 19661: 1.0,\n",
       " 19708: 0.3333333333333333,\n",
       " 19748: 0.25,\n",
       " 19749: 0.5,\n",
       " 19793: 0.75,\n",
       " 19797: 1.0,\n",
       " 19868: 0.25,\n",
       " 19922: 0.27586206896551724,\n",
       " 19925: 0.75,\n",
       " 19926: 0.3333333333333333,\n",
       " 19947: 1.0,\n",
       " 19990: 1.0,\n",
       " 20031: 0.5,\n",
       " 20051: 0.3333333333333333,\n",
       " 20106: 1.0,\n",
       " 20131: 0.7058823529411765,\n",
       " 20133: 0.14285714285714285,\n",
       " 20134: 0.14285714285714285,\n",
       " 20145: 0.5,\n",
       " 20209: 0.5,\n",
       " 20264: 0.8,\n",
       " 20265: 0.5,\n",
       " 20308: 0.1,\n",
       " 20357: 1.0,\n",
       " 20371: 0.5,\n",
       " 20428: 0.6666666666666666,\n",
       " 20461: 1.0,\n",
       " 20527: 0.5,\n",
       " 20529: 0.5,\n",
       " 20531: 1.0,\n",
       " 20630: 0.3333333333333333,\n",
       " 20732: 1.0,\n",
       " 20767: 0.16666666666666666,\n",
       " 20775: 0.2,\n",
       " 20782: 0.2,\n",
       " 20870: 0.5,\n",
       " 21501: 1.0,\n",
       " 21915: 0.5,\n",
       " 22870: 0.5,\n",
       " 24226: 0.3333333333333333,\n",
       " 24234: 0.25,\n",
       " 24692: 0.5,\n",
       " 26030: 0.16666666666666666,\n",
       " 26093: 0.6666666666666666,\n",
       " 26134: 0.5,\n",
       " 26175: 0.125,\n",
       " 26392: 1.0,\n",
       " 26480: 0.3333333333333333,\n",
       " 26562: 0.5,\n",
       " 26577: 0.3,\n",
       " 26605: 0.5,\n",
       " 26733: 1.0,\n",
       " 26907: 1.0,\n",
       " 27099: 0.5,\n",
       " 27514: 0.3333333333333333,\n",
       " 28003: 1.0,\n",
       " 28020: 0.75,\n",
       " 28315: 1.0,\n",
       " 28437: 0.3333333333333333,\n",
       " 28499: 0.125,\n",
       " 28584: 0.5,\n",
       " 28826: 0.6,\n",
       " 29220: 1.0,\n",
       " 29309: 0.5,\n",
       " 30084: 0.3333333333333333,\n",
       " 30266: 0.3333333333333333,\n",
       " 30360: 0.2,\n",
       " 30491: 1.0,\n",
       " 30531: 0.2222222222222222,\n",
       " 31229: 0.8571428571428571,\n",
       " 31378: 0.25,\n",
       " 32280: 0.5,\n",
       " 33482: 0.5,\n",
       " 33519: 0.6363636363636364,\n",
       " 33521: 0.2962962962962963,\n",
       " 33579: 0.5,\n",
       " 33585: 1.0,\n",
       " 33614: 0.6666666666666666,\n",
       " 33620: 1.0,\n",
       " 33639: 0.5,\n",
       " 33665: 0.3333333333333333,\n",
       " 33735: 0.3333333333333333,\n",
       " 33745: 0.16666666666666666,\n",
       " 33910: 1.0,\n",
       " 33918: 1.0,\n",
       " 33961: 0.25,\n",
       " 33972: 0.0625,\n",
       " 33994: 0.4,\n",
       " 34104: 0.6,\n",
       " 34105: 0.6666666666666666,\n",
       " 34106: 0.5,\n",
       " 34108: 0.047619047619047616,\n",
       " 34152: 0.5,\n",
       " 34195: 0.3333333333333333,\n",
       " 34236: 1.0,\n",
       " 34306: 1.0,\n",
       " 34476: 1.0,\n",
       " 34494: 0.75,\n",
       " 34506: 1.0,\n",
       " 34558: 0.6666666666666666,\n",
       " 34606: 0.23076923076923078,\n",
       " 34612: 0.6666666666666666,\n",
       " 34619: 1.0,\n",
       " 34668: 0.5,\n",
       " 34679: 0.5,\n",
       " 34694: 0.4,\n",
       " 34702: 1.0,\n",
       " 34719: 1.0,\n",
       " 35429: 0.2,\n",
       " 35465: 0.375,\n",
       " 35466: 0.125,\n",
       " 35468: 1.0,\n",
       " 35505: 0.2222222222222222,\n",
       " 35511: 0.2857142857142857,\n",
       " 35520: 1.0,\n",
       " 35523: 0.6,\n",
       " 35581: 0.2857142857142857,\n",
       " 35593: 1.0,\n",
       " 35635: 1.0,\n",
       " 35663: 0.6818181818181818,\n",
       " 35675: 0.2,\n",
       " 35680: 0.5,\n",
       " 35739: 0.5,\n",
       " 35856: 1.0,\n",
       " 35875: 0.3333333333333333,\n",
       " 36021: 0.4,\n",
       " 36094: 0.5,\n",
       " 36181: 0.5,\n",
       " 36244: 0.5,\n",
       " 36319: 1.0,\n",
       " 36560: 1.0,\n",
       " 37642: 0.6666666666666666,\n",
       " 37839: 1.0,\n",
       " 37868: 0.5,\n",
       " 37895: 1.0,\n",
       " 38005: 0.3333333333333333,\n",
       " 38102: 0.5,\n",
       " 38723: 1.0,\n",
       " 38848: 1.0,\n",
       " 38894: 0.5,\n",
       " 39389: 0.2647058823529412,\n",
       " 39796: 0.5,\n",
       " 39886: 0.25,\n",
       " 39893: 0.6666666666666666,\n",
       " 40200: 1.0,\n",
       " 42621: 0.5,\n",
       " 42761: 0.5,\n",
       " 43162: 0.3333333333333333,\n",
       " 43445: 0.5,\n",
       " 45822: 1.0,\n",
       " 46238: 1.0,\n",
       " 46243: 0.25,\n",
       " 48623: 0.375,\n",
       " 48809: 0.5,\n",
       " 48810: 0.2727272727272727,\n",
       " 49427: 1.0,\n",
       " 50634: 0.5,\n",
       " 50635: 0.8,\n",
       " 50694: 0.42857142857142855,\n",
       " 50743: 0.4,\n",
       " 50791: 0.3333333333333333,\n",
       " 50808: 0.25,\n",
       " 51527: 0.6666666666666666,\n",
       " 52150: 0.125,\n",
       " 52188: 0.3333333333333333,\n",
       " 52247: 0.25,\n",
       " 52819: 1.0,\n",
       " 52890: 0.14285714285714285,\n",
       " 53167: 1.0,\n",
       " 55450: 0.3333333333333333,\n",
       " 56013: 0.3333333333333333,\n",
       " 56678: 1.0,\n",
       " 58359: 1.0,\n",
       " 59383: 0.3076923076923077,\n",
       " 60374: 0.6666666666666666,\n",
       " 61475: 0.15,\n",
       " 61476: 0.3333333333333333,\n",
       " 61492: 1.0,\n",
       " 61767: 1.0,\n",
       " 61860: 0.3333333333333333,\n",
       " 61874: 0.2857142857142857,\n",
       " 61888: 0.5,\n",
       " 62124: 0.6666666666666666,\n",
       " 62156: 0.25,\n",
       " 62337: 0.6666666666666666,\n",
       " 63186: 0.5,\n",
       " 63442: 0.16666666666666666,\n",
       " 65428: 0.14285714285714285,\n",
       " 65515: 0.6,\n",
       " 65896: 0.14285714285714285,\n",
       " 69101: 0.5,\n",
       " 69219: 1.0,\n",
       " 69346: 0.16666666666666666,\n",
       " 69403: 0.42857142857142855,\n",
       " 69857: 0.6666666666666666,\n",
       " 69858: 0.5,\n",
       " 71243: 0.5,\n",
       " 71292: 0.16666666666666666,\n",
       " 71298: 1.0,\n",
       " 71727: 0.5,\n",
       " 71953: 0.5,\n",
       " 72610: 0.14285714285714285,\n",
       " 72839: 0.2857142857142857,\n",
       " 75082: 0.3333333333333333,\n",
       " 75256: 0.3333333333333333,\n",
       " 75279: 0.2,\n",
       " 75280: 1.0,\n",
       " 76608: 0.5,\n",
       " 77216: 0.5,\n",
       " 78006: 0.3333333333333333,\n",
       " 78112: 0.3333333333333333,\n",
       " 78113: 0.3333333333333333,\n",
       " 78364: 1.0,\n",
       " 78414: 1.0,\n",
       " 78614: 0.07692307692307693,\n",
       " 78934: 0.3333333333333333,\n",
       " 78964: 0.09090909090909091,\n",
       " 79069: 0.25,\n",
       " 79188: 0.5,\n",
       " 82074: 0.5,\n",
       " 82733: 0.2222222222222222,\n",
       " 82738: 0.5,\n",
       " 82740: 0.6666666666666666,\n",
       " 83853: 1.0,\n",
       " 83916: 0.3333333333333333,\n",
       " 84014: 0.125,\n",
       " 84107: 0.16666666666666666,\n",
       " 84164: 0.16666666666666666,\n",
       " 84319: 1.0,\n",
       " 85807: 0.25,\n",
       " 85897: 0.6666666666666666,\n",
       " 85913: 0.125,\n",
       " 85918: 0.16666666666666666,\n",
       " 85981: 0.3333333333333333,\n",
       " 86345: 0.375,\n",
       " 86753: 1.0,\n",
       " 87329: 0.2222222222222222,\n",
       " 87481: 0.10714285714285714,\n",
       " 87979: 1.0,\n",
       " 88202: 1.0,\n",
       " 88971: 1.0,\n",
       " 89464: 0.6,\n",
       " 90849: 0.3333333333333333,\n",
       " 91948: 0.3333333333333333,\n",
       " 95318: 1.0,\n",
       " 98765: 0.3333333333333333,\n",
       " 98863: 0.5,\n",
       " 99420: 0.5,\n",
       " 100282: 1.0,\n",
       " 101290: 0.1111111111111111,\n",
       " 101467: 0.3888888888888889,\n",
       " 102551: 1.0,\n",
       " 102667: 0.6666666666666666,\n",
       " 103676: 0.5,\n",
       " 103703: 1.0,\n",
       " 103704: 0.5,\n",
       " 104392: 0.5,\n",
       " 107377: 0.25,\n",
       " 107800: 0.25,\n",
       " 109641: 0.25,\n",
       " 111296: 0.125,\n",
       " 111328: 0.5,\n",
       " 111414: 1.0,\n",
       " 112737: 0.3333333333333333,\n",
       " 113162: 0.08333333333333333,\n",
       " 113168: 0.6666666666666666,\n",
       " 113172: 0.16666666666666666,\n",
       " 113185: 0.6,\n",
       " 113236: 0.75,\n",
       " 113271: 0.16666666666666666,\n",
       " 113636: 0.25,\n",
       " 113647: 0.1111111111111111,\n",
       " 113654: 1.0,\n",
       " 113655: 1.0,\n",
       " 113674: 0.5,\n",
       " 113690: 0.5,\n",
       " 113691: 0.26666666666666666,\n",
       " 113706: 0.25,\n",
       " 113740: 0.2,\n",
       " 113742: 0.16666666666666666,\n",
       " 113753: 0.14285714285714285,\n",
       " 113755: 0.5714285714285714,\n",
       " 113768: 1.0,\n",
       " 113807: 0.8181818181818182,\n",
       " 113813: 0.5,\n",
       " 113822: 0.3333333333333333,\n",
       " 113836: 0.5,\n",
       " 113851: 0.14285714285714285,\n",
       " 113872: 0.3333333333333333,\n",
       " 113885: 1.0,\n",
       " 113886: 0.2,\n",
       " 113946: 0.2,\n",
       " 113964: 0.42857142857142855,\n",
       " 114001: 0.3333333333333333,\n",
       " 114002: 1.0,\n",
       " 114009: 0.5,\n",
       " 114018: 0.5,\n",
       " 114019: 1.0,\n",
       " 114030: 0.2727272727272727,\n",
       " 114046: 0.2,\n",
       " 114115: 1.0,\n",
       " 114121: 1.0,\n",
       " 114179: 1.0,\n",
       " 114194: 0.25,\n",
       " 114199: 0.3333333333333333,\n",
       " 114231: 1.0,\n",
       " 114327: 1.0,\n",
       " 114329: 1.0,\n",
       " 114338: 0.16666666666666666,\n",
       " 114376: 0.5,\n",
       " 114384: 0.5,\n",
       " 114386: 0.5,\n",
       " 114404: 0.2857142857142857,\n",
       " 114406: 0.5,\n",
       " 114417: 0.3888888888888889,\n",
       " 114442: 0.2222222222222222,\n",
       " 114443: 0.375,\n",
       " 114477: 1.0,\n",
       " 114500: 0.3333333333333333,\n",
       " 114527: 0.6666666666666666,\n",
       " 114528: 0.13333333333333333,\n",
       " 114544: 0.2,\n",
       " 114548: 0.5,\n",
       " 114617: 0.14285714285714285,\n",
       " 114645: 0.5,\n",
       " 114649: 0.3333333333333333,\n",
       " 114663: 0.2,\n",
       " 114717: 0.3333333333333333,\n",
       " 114740: 1.0,\n",
       " 114826: 0.3333333333333333,\n",
       " 114832: 0.25,\n",
       " 114837: 0.3333333333333333,\n",
       " 115761: 1.0,\n",
       " 116669: 1.0,\n",
       " 117239: 0.16666666666666666,\n",
       " 122827: 0.5,\n",
       " 124106: 0.2857142857142857,\n",
       " 124190: 0.5,\n",
       " 124231: 0.2,\n",
       " 124277: 0.3333333333333333,\n",
       " 124335: 0.4,\n",
       " 124340: 0.25,\n",
       " 124390: 0.5,\n",
       " 124761: 0.2857142857142857,\n",
       " 125451: 0.5,\n",
       " 125983: 0.5,\n",
       " 126543: 0.6666666666666666,\n",
       " 128854: 1.0,\n",
       " 129979: 0.2,\n",
       " 130079: 1.0,\n",
       " 134013: 0.5,\n",
       " 134129: 0.5,\n",
       " 134381: 0.5,\n",
       " 136813: 0.3333333333333333,\n",
       " 139241: 0.3333333333333333,\n",
       " 143606: 1.0,\n",
       " 146487: 1.0,\n",
       " 146901: 0.5,\n",
       " 147883: 0.125,\n",
       " 148918: 0.5,\n",
       " 148924: 0.2857142857142857,\n",
       " 149004: 1.0,\n",
       " 149074: 0.2222222222222222,\n",
       " 149075: 0.25,\n",
       " 149211: 0.3333333333333333,\n",
       " 149378: 0.3333333333333333,\n",
       " 149386: 1.0,\n",
       " 152125: 0.6666666666666666,\n",
       " 152169: 0.5,\n",
       " 152441: 0.6666666666666666,\n",
       " 152492: 0.25,\n",
       " 152562: 0.16666666666666666,\n",
       " 152582: 0.25,\n",
       " 152628: 0.5,\n",
       " 153317: 1.0,\n",
       " 154303: 1.0,\n",
       " 154894: 0.4,\n",
       " 154944: 1.0,\n",
       " 154946: 0.2,\n",
       " 157910: 0.3333333333333333,\n",
       " 158677: 0.3333333333333333,\n",
       " 159944: 1.0,\n",
       " 162027: 0.5,\n",
       " 162926: 1.0,\n",
       " 164024: 0.3333333333333333,\n",
       " 164099: 1.0,\n",
       " 164399: 0.75,\n",
       " 165633: 0.2,\n",
       " 168310: 1.0,\n",
       " 171091: 0.5,\n",
       " 171322: 0.5,\n",
       " 171336: 0.5,\n",
       " 171371: 0.5,\n",
       " 173228: 1.0,\n",
       " 173254: 0.5,\n",
       " 173289: 1.0,\n",
       " 173551: 0.3333333333333333,\n",
       " 175476: 0.2857142857142857,\n",
       " 175597: 0.8,\n",
       " 175609: 1.0,\n",
       " 175610: 1.0,\n",
       " 175732: 0.3333333333333333,\n",
       " 175738: 0.5,\n",
       " 175740: 1.0,\n",
       " 177026: 0.3333333333333333,\n",
       " 185732: 1.0,\n",
       " 193280: 0.2,\n",
       " 196002: 1.0,\n",
       " 196442: 1.0,\n",
       " 198378: 0.14285714285714285,\n",
       " 211388: 0.5,\n",
       " 225258: 0.5,\n",
       " 229862: 0.8333333333333334,\n",
       " 231522: 1.0,\n",
       " 237278: 0.3333333333333333,\n",
       " 242690: 0.5,\n",
       " 242818: 0.5,\n",
       " 248787: 0.5,\n",
       " 250603: 0.5,\n",
       " 257894: 0.5,\n",
       " 260225: 1.0,\n",
       " 260272: 0.3333333333333333,\n",
       " 260314: 1.0,\n",
       " 260366: 0.6923076923076923,\n",
       " 260409: 0.5,\n",
       " 260491: 1.0,\n",
       " 260574: 0.23076923076923078,\n",
       " 260590: 0.4,\n",
       " 260635: 0.3333333333333333,\n",
       " 260658: 0.25,\n",
       " 260668: 0.5,\n",
       " 260705: 0.5,\n",
       " 260731: 0.3333333333333333,\n",
       " 260843: 1.0,\n",
       " 260916: 0.45454545454545453,\n",
       " 260950: 1.0,\n",
       " 260992: 1.0,\n",
       " 260996: 0.5,\n",
       " 261091: 1.0,\n",
       " 261092: 1.0,\n",
       " 261155: 0.3333333333333333,\n",
       " 261156: 1.0,\n",
       " 261165: 0.6,\n",
       " 261193: 0.3333333333333333,\n",
       " 261239: 0.6666666666666666,\n",
       " 261269: 0.5,\n",
       " 261342: 1.0,\n",
       " 261355: 1.0,\n",
       " 261397: 1.0,\n",
       " 261560: 1.0,\n",
       " 261573: 0.3333333333333333,\n",
       " 261583: 1.0,\n",
       " 261677: 1.0,\n",
       " 261696: 1.0,\n",
       " 261801: 0.25,\n",
       " 261825: 1.0,\n",
       " 261840: 0.3333333333333333,\n",
       " 262002: 0.25,\n",
       " 262027: 0.3333333333333333,\n",
       " 273383: 1.0,\n",
       " 275249: 0.5,\n",
       " 276189: 0.5,\n",
       " 281146: 0.6666666666666666,\n",
       " 282818: 0.5,\n",
       " 282826: 1.0,\n",
       " 283017: 1.0,\n",
       " 283055: 1.0,\n",
       " 296052: 1.0,\n",
       " 299223: 0.5,\n",
       " 303388: 0.5,\n",
       " 316568: 0.6666666666666666,\n",
       " 316618: 1.0,\n",
       " 317087: 0.3333333333333333,\n",
       " 322292: 1.0,\n",
       " 322887: 0.6666666666666666,\n",
       " 324102: 1.0,\n",
       " 328308: 1.0,\n",
       " 345549: 0.5,\n",
       " 346817: 0.3333333333333333,\n",
       " 363610: 1.0,\n",
       " 366178: 0.5,\n",
       " 366194: 0.5,\n",
       " 366209: 0.75,\n",
       " 366247: 1.0,\n",
       " 366261: 0.5,\n",
       " 366362: 1.0,\n",
       " 366417: 1.0,\n",
       " 366455: 1.0,\n",
       " 366463: 0.5,\n",
       " 366481: 0.5,\n",
       " 366504: 1.0,\n",
       " 366505: 0.5,\n",
       " 366565: 1.0,\n",
       " 366585: 0.5,\n",
       " 366594: 1.0,\n",
       " 366654: 1.0,\n",
       " 366681: 1.0,\n",
       " 366696: 1.0,\n",
       " 378515: 0.2,\n",
       " 391330: 1.0,\n",
       " 398252: 1.0,\n",
       " 398253: 0.3333333333333333,\n",
       " 421061: 1.0,\n",
       " 421065: 1.0,\n",
       " 421096: 1.0,\n",
       " 421287: 1.0,\n",
       " 421299: 0.5,\n",
       " 421333: 1.0,\n",
       " 421337: 1.0,\n",
       " 421343: 1.0,\n",
       " 421405: 1.0,\n",
       " 421415: 0.5,\n",
       " 421470: 1.0,\n",
       " 421473: 0.5,\n",
       " 421482: 0.5,\n",
       " 421571: 0.3333333333333333,\n",
       " 421605: 1.0,\n",
       " 422842: 0.5,\n",
       " 438297: 1.0,\n",
       " 438393: 0.5}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apa_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 86193, 278258, 278358, 278628, 278689, 278692, 278777, 279003,\n",
       "       279048, 437079, 552217, 552258, 626903, 627029], dtype=int32)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_ap.getrow(13319).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9096, 13319, 15481, 39389, 48809], dtype=int32)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_pa.getrow(86193).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13319, 15481, 39389, 48809], dtype=int32)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_pa.getrow(278258).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9096, 13319, 48809], dtype=int32)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_pa.getrow(278358).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4386,  13319,  15481,  48809, 248787], dtype=int32)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_pa.getrow(278628).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = pd.read_csv('paper_tmp.txt', sep='\\t', names=['no','paper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5201    FONN: Combining First Order Logic with Connect...\n",
       "5202    Approximate Value Trees in Structured Dynamic ...\n",
       "5203    On a theory of learning with similarity functi...\n",
       "5204    Learning Word Association Norms Using Tree Cut...\n",
       "5205    Associative Reinforcement Learning using Linea...\n",
       "5206    On-line Learning of Binary Lexical Relations U...\n",
       "5207    Toward a Model of Mind as a Laissez-Faire Econ...\n",
       "5208    A New Method for Predicting Protein Secondary ...\n",
       "5209               Semi-supervised Clustering by Seeding.\n",
       "5210    Query Learning Strategies Using Boosting and B...\n",
       "5211    Learning to Optimally Schedule Internet Banner...\n",
       "5212    Multi-way distributional clustering via pairwi...\n",
       "5213    Convergence Problems of General-Sum Multiagent...\n",
       "5214                         Action respecting embedding.\n",
       "5215    Learning Recursive Relations with Randomly Sel...\n",
       "5216          A Column Generation Algorithm For Boosting.\n",
       "5217             Duality and Geometry in SVM Classifiers.\n",
       "5218    Learning predictive state representations usin...\n",
       "5219    Model Selection Criteria for Learning Belief N...\n",
       "5220    Learning Logic Programs for Layout Analysis Co...\n",
       "5221    Reducing Multiclass to Binary: A Unifying Appr...\n",
       "5222    Gaussian process classification for segmenting...\n",
       "5223              Regression Error Characteristic Curves.\n",
       "5224    Feature Subset Selection and Order Identificat...\n",
       "5225    Active learning for Hidden Markov Models: obje...\n",
       "5226    A Nonparametric Approach to Noisy and Costly O...\n",
       "5227    Multiple kernel learning, conic duality, and t...\n",
       "5228                         Tempering for Bayesian C&RT.\n",
       "5229    Integrating constraints and metric learning in...\n",
       "5230                Fast condensed nearest neighbor rule.\n",
       "                              ...                        \n",
       "5806     Graph clustering with network structure indices.\n",
       "5807    On the role of tracking in stationary environm...\n",
       "5808    Piecewise pseudolikelihood for efficient train...\n",
       "5809    Transductive regression piloted by inter-manif...\n",
       "5810    Efficient bandit algorithms for online multicl...\n",
       "5811    Unsupervised rank aggregation with distance-ba...\n",
       "5812    Closed-form supervised dimensionality reductio...\n",
       "5813    Dirichlet component analysis: feature extracti...\n",
       "5814    Pairwise constraint propagation by semidefinit...\n",
       "5815    An asymptotic analysis of generative, discrimi...\n",
       "5816       An HDP-HMM for systems with state persistence.\n",
       "5817               Rank minimization via online learning.\n",
       "5818    An analysis of linear models, linear value-fun...\n",
       "5819      Efficient multiclass maximum margin clustering.\n",
       "5820    Discriminative structure and parameter learnin...\n",
       "5821       Multi-task learning for HIV therapy screening.\n",
       "5822    On the hardness of finding symmetries in Marko...\n",
       "5823               Modeling interleaved hidden processes.\n",
       "5824    Fast solvers and efficient implementations for...\n",
       "5825    Reinforcement learning with limited reinforcem...\n",
       "5826    Online kernel selection for Bayesian reinforce...\n",
       "5827    Non-parametric policy gradients: a unified tre...\n",
       "5828    Nonnegative matrix factorization via rank-one ...\n",
       "5829    Classification using discriminative restricted...\n",
       "5830    Extracting and composing robust features with ...\n",
       "5831    Accurate max-margin training for structured ou...\n",
       "5832    SVM optimization: inverse dependence on traini...\n",
       "5833    Bi-level path following for cross validated so...\n",
       "5834     Graph transduction via alternating minimization.\n",
       "5835    Sample-based learning and search with permanen...\n",
       "Name: paper, Length: 635, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper[paper['no'].isin(A_ap.getrow(27961).nonzero()[1])]['paper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_apcpa = ((A_ap.dot(A_pc)).dot(A_cp)).dot(A_pa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<472636x472636 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 38905173 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_apcpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yseongjun/anaconda3/envs/recsys/lib/python3.6/site-packages/scipy/sparse/compressed.py:746: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "A_apcpa.setdiag(0)\n",
    "A_apcpa.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x472636 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5572 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_apcpa.getrow(13319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00017409734235639948"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "38890698/(472636*472636)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = A_apcpa.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_counts = np.unique(indices[0], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    76,    124,    192, ..., 453713, 472633, 472635], dtype=int32),\n",
       " array([2509, 4765, 2861, ...,  941,   44,   44]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
